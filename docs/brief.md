# Project Brief: Relative Performance Machine (RPM) 1.3

## Executive Summary
The Relative Performance Machine (RPM) 1.3 is an advanced, AI-enhanced software platform designed to provide deep performance analysis and diagnostics for solar energy assets. The primary problem it solves is the inefficient and fragmented process asset managers face when trying to identify performance degradation and pinpoint its root cause across a complex, hierarchical system of sites, skids, and inverters. The initial target market is the internal asset management team, with the platform being built as a scalable, enterprise-grade tool suitable for wider adoption. The key value proposition of RPM 1.3 is its ability to rapidly guide a user from high-level anomaly detection to granular root-cause analysis through an intuitive, multi-layered visualization interface, which is enhanced by an AI-powered natural language query tool to provide seamless diagnostics.

## Problem Statement
The core problem is a critical inefficiency in the workflow used to diagnose energy production shortfalls, which directly impacts revenue and operational costs. The current process is manual, reactive, and lacks the integrated tools required for rapid root-cause analysis, despite having data available in a central Redshift database.

This manifests in the following key challenges that RPM 1.3 will solve:
* **Inefficient, Multi-Level Troubleshooting**: Asset managers cannot efficiently trace underperformance from a high-level site view down to the specific faulty component. The current workflow requires manual data pulls and exporting data to external tools like Excel for detailed, layer-by-layer analysis. This turns what should be a minutes-long investigation into a process that takes hours or even weeks.
* **Lack of Integrated Visualization**: There is no single interface that provides the necessary hierarchical views (Site → Skid → Inverter) required for effective troubleshooting. Furthermore, the inability to properly visualize actual production against expected models—or to overlay critical data like irradiance—prevents quick identification of performance deviations.
* **Inadequate Data Filtering and Quality Control**: The current analysis is hampered by data noise and the inability to apply critical filters. Key data, such as identifying periods where inverters have 100% availability, is not easily isolated, leading to inaccurate conclusions. There is no standardized method for aggregating data at appropriate intervals to reveal meaningful trends.
* **Reactive vs. Proactive Analysis**: The existing workflow is entirely reactive, providing day-after analysis at best. There are no automated, real-time alerts for underperforming components or proactive insights generated by an intelligent system. Asset managers must manually discover problems rather than being automatically notified.

This project will solve these problems by building a scalable MVP that provides an integrated, visual, and AI-enhanced platform for performance analysis. This will empower the entire DESRI team to move from reactive troubleshooting to proactive asset management.

## Proposed Solution
The proposed solution is the **Relative Performance Machine (RPM) 1.3**, an integrated, web-based software platform for the proactive management of solar energy assets. The core of the solution is a powerful visualization engine that allows users to seamlessly conduct hierarchical, time-series analysis—drilling down from a portfolio-wide view to individual sites, skids, and inverters—to compare actual performance against expected models.

RPM 1.3's key differentiator is its **AI-powered diagnostic assistant**. This feature allows asset managers to use natural language queries (via text or speech) to investigate anomalies, generate custom reports, and receive proactive recommendations. This transforms the current manual, reactive analysis into an efficient, guided, and proactive workflow.

This solution will succeed by directly replacing the fragmented, time-consuming process. By providing a single, intuitive interface for the entire diagnostic journey, RPM 1.3 will drastically reduce the time required to identify and address underperformance. The high-level vision is for RPM 1.3 to become the standard, enterprise-wide platform for asset management at DESRI, enabling a shift from reactive problem-solving to proactive, AI-driven portfolio optimization.

## Target Users
### Primary User Segment: Solar Asset Manager
* **Profile**: A professional with a background in finance, engineering, or data analysis, responsible for the financial and operational performance of a portfolio of solar assets.
* **Current Behaviors**: Their current workflow is fragmented and manual, requiring them to access multiple software platforms and export data to spreadsheets for diagnostics.
* **Needs & Pain Points**: They need a single, efficient tool to quickly identify underperformance and its root cause. Their primary pain points are lost revenue from asset downtime and operational inefficiency.
* **Goals**: To maximize asset uptime and energy production, meet financial targets, and reduce the time and cost associated with troubleshooting.

### Secondary User Segment: O&M Field Technician
* **Profile**: A technical professional responsible for on-site maintenance and repair of solar farm components.
* **Needs & Pain Points**: They need precise, component-level diagnostic information *before* arriving on site to avoid wasted time and multiple trips.
* **Goals**: To resolve issues correctly and efficiently on the first site visit.

## Goals & Success Metrics
### Business Objectives
* Successfully deliver a feature-complete MVP of RPM 1.3 by **August 15th, 2025**, for a key stakeholder presentation.
* Reduce the average time required to identify the root cause of a site underperformance event.
* Increase asset energy production and revenue by minimizing the duration of fault-related downtime.
* Streamline the asset management diagnostic workflow into a single, efficient platform.

### User Success Metrics
* **Reduced Time-to-Insight**: The time it takes for an Asset Manager to go from seeing a site-level issue to identifying the specific underperforming component is drastically reduced.
* **Increased Diagnostic Confidence**: Asset Managers can trust the data and the model, allowing them to make faster, more confident dispatch decisions.
* **Proactive Management**: A shift from discovering issues reactively to being proactively notified by the AI assistant about potential problems.

### Key Performance Indicators (KPIs)
* **Time-to-Root-Cause**: The average time from initial performance anomaly detection to root-cause identification.
* **Lost Production Volume**: MWh of energy lost due to diagnosed faults, tracked for a downward trend.
* **AI Assistant Effectiveness**: The percentage of proactive AI suggestions that lead to the identification of a valid performance issue.

## MVP Scope
### Core Features (Must Have for Aug 15th)
* **Hierarchical Performance Visualization**: The core drill-down functionality from the **Site** level, down to the **Skid**, and then to the individual **Inverter**.
* **Power Curve Plotting**: The ability to plot actual vs. expected power curves with specified visualization and statistical measures (RMSE/R-squared).
* **100% Inverter Availability Filter**: A critical data quality filter to ensure the power curve analysis is accurate.
* **AI Assistant (Reactive Query)**: The initial version of the AI chatbot that can respond to user-typed queries, providing a text summary and generating a supporting chart.
* **Basic Customizable Dashboard**: The ability for a user to arrange a dashboard with core widgets and save their layout.

### Out of Scope (For Post-MVP Release)
* **Combiner Box Level Analysis**
* **Proactive AI Suggestions**
* **Speech-to-Text / Text-to-Speech**
* **Integration with Other Data Platforms**

### MVP Success Criteria
* An Asset Manager can use the tool to successfully identify a site-level underperformance event and trace it to a specific faulty inverter in under 5 minutes.
* The AI assistant can correctly answer the top five predefined diagnostic questions.
* The platform is deployed and fully functional for the stakeholder presentation on **August 19th**.

## Post-MVP Vision
### Phase 2 Features
* **Granular Analysis**: Introduce the Combiner Box level analysis view.
* **Proactive AI**: Enhance the AI assistant to provide proactive alerts and suggestions.
* **Voice Interface**: Implement the Speech-to-Text/Text-to-Speech functionality.

### Long-term Vision
* Evolve RPM 1.3 into the enterprise-standard platform for all DESRI assets, incorporating predictive maintenance capabilities.

### Expansion Opportunities
* Integrate with other data platforms.
* Incorporate advanced weather correlation analysis.
* Provide automated work order recommendations for O&M dispatch.

## Technical Considerations
### Platform Requirements
* **Target Platforms**: A cloud-native web application targeting modern desktop browsers.
* **Performance Requirements**: Database queries must return results in seconds.

### Technology Preferences
* **Frontend**: A modern framework like **React or Next.js** is recommended, using a component toolkit like **ShadCN**. An alternative to consider is **Streamlit**.
* **Backend**: A **Python-based framework** (e.g., FastAPI, Flask).
* **Database**: **AWS Redshift**.
* **Hosting/Infrastructure**: **Amazon Web Services (AWS)**.

### Architecture Considerations
* **Scalability**: Must scale beyond the initial eight sites.
* **Service Architecture**: A decoupled architecture (e.g., microservices or serverless) is recommended.
* **Security**: The platform will require user authentication and authorization.

## Constraints & Assumptions
### Constraints
* **Timeline**: MVP must be delivered by **August 15th, 2025**.
* **Budget**: To be determined.
* **Resources**: Development will be executed by the BMad agent team.
* **Technical**: Must use the existing **AWS Redshift** database and be hosted on **AWS**.

### Key Assumptions
* **Data Availability**: The necessary relational data exists in the AWS Redshift database.
* **Model & Data Structure**: The final `8760.xlsx` data file will conform to the structure of the provided template.
* **Stakeholder Availability**: The asset management team will be available for periodic feedback.

## Risks & Open Questions
### Key Risks
* **Data Structure Mismatch (High)**: The actual data in Redshift or the final data file does not match the inferred structure.
* **Query Performance (Medium)**: Data volume may present performance challenges.
* **Tight Deadline (Medium)**: The deadline is aggressive for an MVP with AI components.

### Open Questions
* What are the specific performance targets (e.g., maximum query response time)?
* What are the detailed user authentication and authorization requirements?
* Who is the definitive technical owner of the AWS Redshift data schema?

### Areas Needing Further Research
* The optimal AWS infrastructure for hosting the AI components.
* The best technical approach for saving user-customized dashboards.